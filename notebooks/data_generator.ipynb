{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from typing import List, Tuple, Dict, Optional, Union, Any\n",
    "\n",
    "import numpy as np\n",
    "import babel\n",
    "import nlpaug.augmenter.char as nac\n",
    "from babel.dates import format_date, format_datetime\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    TimeDistributed,\n",
    "    Embedding,                               \n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "os.chdir(\"/Users/danny/Desktop/lazydate\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read wikitext-103\n",
    "with open('data/wiki.train.raw', 'r') as f:\n",
    "    wikitext = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_sentences = sent_tokenize(wikitext[:10000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Irish rugby has become increasingly competitive at both the international and provincial levels since the sport went professional in 1994 .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(wiki_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_formats = [\"d\", \"dd\"]\n",
    "month_formats = [\"M\", \"MM\", \"MMM\", \"MMMM\", \"MMMM\", \"L\", \"LL\", \"LLL\", \"LLLL\", \"LLLL\"]\n",
    "year_formats = [\"yy\", \"yyyy\" ]\n",
    "\n",
    "second_formats = [\"s\", \"ss\"]\n",
    "minute_formats = [\"m\", \"mm\"]\n",
    "hour_formats = [\"h\", \"hh\", \"H\", \"HH\"]\n",
    "timezone_formats = [\"\", \"\", \"\", \"\", \"\", \"z\", \"zz\", \"zzz\", \"zzzz\"]\n",
    "time_separators = [\":\"]\n",
    "\n",
    "separator_frequency = {\n",
    "    \".\": 0.1, \n",
    "    \"/\": 0.15, \n",
    "    \"-\": 0.15, \n",
    "    \"''\": 0.1,\n",
    "    \" \": 0.5, \n",
    "}\n",
    "\n",
    "built_in_formats = [\"short\", \"medium\", \"long\", \"full\"]\n",
    "\n",
    "locales = babel.localedata.locale_identifiers()\n",
    "locales = [l for l in locales if \"en_\" in l]\n",
    "\n",
    "\n",
    "def random_date(n_years: int = 100) -> Tuple[datetime.datetime, Dict[str, int]]:\n",
    "    start_date = datetime.datetime(1900, 1, 1, 0, 0, 0)\n",
    "    gen_dict = {\n",
    "        \"days\": np.random.randint(0, n_years * 265),\n",
    "        \"hours\": np.random.randint(0, 24),\n",
    "        \"minutes\": np.random.randint(0, 60),\n",
    "        \"seconds\": np.random.randint(0, 60),\n",
    "    }\n",
    "    \n",
    "    date = start_date + datetime.timedelta(**gen_dict)\n",
    "    return date, gen_dict\n",
    "\n",
    "\n",
    "def random_format(date: datetime.datetime) -> Tuple[str, Dict[str, str]]:\n",
    "    possible_separators = list(separator_frequency.keys())\n",
    "    \n",
    "    if date.year >= datetime.datetime.now().year + 1:\n",
    "        year_format = np.random.choice(year_formats)\n",
    "    else:\n",
    "        year_format = \"yyyy\"\n",
    "    \n",
    "    append_time = np.random.rand() <= 0.5\n",
    "    drop_day = date.day == 1 and np.random.rand() <= 0.3\n",
    "    gen_dict = {\n",
    "        \"day\": np.random.choice(day_formats),\n",
    "        \"month\": np.random.choice(month_formats),\n",
    "        \"year\": year_format,\n",
    "        \"separator\": np.random.choice(\n",
    "            possible_separators, p=list(separator_frequency.values())\n",
    "        ),\n",
    "        \"append_time\": append_time,\n",
    "        \"drop_day\": drop_day,\n",
    "    }\n",
    "    if append_time:\n",
    "        time_gen_dict = {\n",
    "            \"second\": np.random.choice(second_formats),\n",
    "            \"minute\": np.random.choice(minute_formats),\n",
    "            \"hour\": np.random.choice(hour_formats),\n",
    "            \"timezone\": np.random.choice(timezone_formats),\n",
    "            \"time_separator\": np.random.choice(time_separators)\n",
    "        }\n",
    "    else:\n",
    "        time_gen_dict = {k: \"\" for k in [\"second\", \"minute\", \"hours\", \"timezone\", \"time_separator\"]}\n",
    "    gen_dict.update(time_gen_dict)\n",
    "    \n",
    "    sep = gen_dict[\"separator\"]\n",
    "    if sep != \"''\" and gen_dict[\"year\"] == \"yy\":\n",
    "        if np.random.random() <= 0.5:\n",
    "            gen_dict[\"year\"] = \"''\" + gen_dict[\"year\"]\n",
    "            \n",
    "    format_date_str = f\"{gen_dict['day']}{sep}{gen_dict['month']}{sep}{gen_dict['year']}\"\n",
    "    format_time_str = \"\"\n",
    "    \n",
    "    if append_time:\n",
    "        sep = gen_dict[\"time_separator\"]\n",
    "        format_time_str = f\" {gen_dict['hour']}{sep}{gen_dict['minute']}\"\n",
    "        if np.random.random() <= 0.5:\n",
    "            format_time_str += f\"{sep}{gen_dict['second']}\"\n",
    "        if np.random.random() <= 0.5:\n",
    "            format_time_str += f\" a\"  # AM / PM\n",
    "        if np.random.random() <= 0.5:\n",
    "            format_time_str += f\" {gen_dict['timezone']}\"    \n",
    "            \n",
    "    format_str = format_date_str + format_time_str\n",
    "    gen_dict[\"format_str\"] = format_str\n",
    "    return format_str, gen_dict\n",
    "\n",
    "\n",
    "def get_random_wiki_sentence() -> str:\n",
    "    idx = np.random.randint(0, len(wiki_sentences))\n",
    "    return wiki_sentences[idx]\n",
    "\n",
    "\n",
    "def random_noise_dict(\n",
    "    date: datetime.datetime, format_dict: Dict[str, str]\n",
    ") -> Dict[str, str]:\n",
    "\n",
    "    append_day_suffix = format_dict[\"day\"] == \"dd\" and np.random.random() <= 0.5\n",
    "    place_in_sentence = np.random.random() <= 0.5\n",
    "    \n",
    "    gen_dict = {\n",
    "        \"locale\": np.random.choice(locales),\n",
    "        \"append_day_suffix\": append_day_suffix,\n",
    "        \"aug_char_action\": np.random.choice([\"insert\", \"substitute\"]),\n",
    "        \"place_in_sentence\": place_in_sentence,\n",
    "        \"sentence\": get_random_wiki_sentence() if place_in_sentence else \"\",\n",
    "    }\n",
    "    \n",
    "    day_suffix = \"\"\n",
    "    if append_day_suffix:\n",
    "        if date.day in [1, 21, 31]:\n",
    "            day_suffix = \"st\"\n",
    "        elif date.day in [2, 22]:\n",
    "            day_suffix = \"st\"\n",
    "        elif date.day in [3, 23]:\n",
    "            day_suffix = \"rd\"\n",
    "        else:\n",
    "            day_suffix = \"th\"\n",
    "    gen_dict[\"day_suffix\"] = day_suffix\n",
    "    \n",
    "    return gen_dict\n",
    "\n",
    "\n",
    "def put_datestr_in_sentence(datestr: str, sentence: str):\n",
    "    split_sentence = sentence.split(\" \")    \n",
    "    idx = np.random.randint(0, len(split_sentence))\n",
    "    split_sentence[idx] = datestr\n",
    "    return \" \".join(split_sentence)\n",
    "\n",
    "\n",
    "def apply_noise(datestr: str, format_dict: Dict[str, str], noise_dict: Dict[str, Any]) -> str:\n",
    "    out = datestr\n",
    "    sep = format_dict[\"separator\"]\n",
    "    sep = sep[0] if len(sep) > 1 else sep\n",
    "    \n",
    "    date_parts = datestr.split(sep)\n",
    "    \n",
    "    if noise_dict[\"append_day_suffix\"]:\n",
    "        date_parts[0] = date_parts[0] + noise_dict[\"day_suffix\"]\n",
    "        \n",
    "    # Add spelling mistake to month name\n",
    "    if len(format_dict[\"month\"]) > 2 and np.random.random() <= 0.3:\n",
    "        aug = nac.RandomCharAug(\n",
    "            action=noise_dict[\"aug_char_action\"],\n",
    "            aug_char_min=1, \n",
    "            aug_char_max=1,\n",
    "        )\n",
    "        date_parts[1] = aug.augment(date_parts[1])\n",
    "        \n",
    "    out = f\"{sep}\".join(date_parts)\n",
    "    \n",
    "    if noise_dict[\"place_in_sentence\"]:\n",
    "        out = put_datestr_in_sentence(out, noise_dict[\"sentence\"])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def generate_date(\n",
    "    no_date_prob: float = 0.1\n",
    ") -> Tuple[str, datetime.datetime, Dict[str, Any]]:\n",
    "    date, date_gen_dict = random_date()\n",
    "    format_str, format_gen_dict = random_format(date)\n",
    "    noise_gen_dict = random_noise_dict(date, format_gen_dict)\n",
    "\n",
    "    datestr = format_datetime(\n",
    "        date, format=format_str, locale=noise_gen_dict[\"locale\"],\n",
    "    )\n",
    "    datestr = apply_noise(datestr, format_gen_dict, noise_gen_dict)\n",
    "    \n",
    "    gen_dict = date_gen_dict\n",
    "    gen_dict.update(format_gen_dict)\n",
    "    gen_dict.update(noise_gen_dict)\n",
    "    gen_dict[\"no_date\"] = False\n",
    "    \n",
    "    # Example with no date\n",
    "    if np.random.random() <= no_date_prob:\n",
    "        date = None\n",
    "        datestr = get_random_wiki_sentence()\n",
    "        gen_dict[\"no_date\"] = True\n",
    "    \n",
    "    return datestr, date, gen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date string: 6 on the 1976 23rd/October/1930 05:27:27  . \"\n",
      "\n",
      "Correct Date: 1930-10-23 05:27:27\n",
      "\n",
      "CPU times: user 1.7 ms, sys: 1.63 ms, total: 3.33 ms\n",
      "Wall time: 3.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "datestr, date, gen_dict = generate_date()\n",
    "print(f\"Date string: {datestr}\\n\")\n",
    "print(f\"Correct Date: {date}\\n\")\n",
    "# print(gen_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTERS = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "DIGITS = \"0123456789\"\n",
    "SYMBOLS = \"£&()[]+-/*;:@_\\\\\\\"'#\" + \"€$%!?,. \"\n",
    "VOCABULARY = LETTERS + DIGITS + SYMBOLS\n",
    "\n",
    "MAX_SEQUENCE_LEN = 150\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "class CharVectorizer:\n",
    "    def __init__(\n",
    "        self, vocabulary: str, max_sequence_len: int = MAX_SEQUENCE_LEN\n",
    "    ):\n",
    "        self.max_sequence_len = max_sequence_len\n",
    "        self.encoder: Dict[str, int] = {c: idx for idx, c in enumerate(list(vocabulary))}\n",
    "        self.encoder[UNK_TOKEN] = len(self.encoder)\n",
    "\n",
    "    @property\n",
    "    def vocabulary(self):\n",
    "        return sorted(list(self.encoder.keys()))\n",
    "\n",
    "    def transform(self, inputs: List[str]) -> np.ndarray:\n",
    "        outputs = [self._get_char_indices_for_word(s) for s in inputs]\n",
    "        outputs = np.array(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def _get_char_indices_for_word(self, text: str) -> np.ndarray:\n",
    "        next_arr = np.zeros([self.max_sequence_len], dtype=np.int32)\n",
    "\n",
    "        for idx, token in enumerate(text):\n",
    "            if idx < self.max_sequence_len:  # truncate end of sentence if too long\n",
    "                if token in self.encoder:\n",
    "                    vocab_idx = self.encoder[token]\n",
    "                else:\n",
    "                    vocab_idx = self.encoder[UNK_TOKEN]\n",
    "                next_arr[idx] = vocab_idx\n",
    "        return next_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, batch_size=32, n_examples=50000):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_examples = n_examples\n",
    "        self.input_vectorizer = CharVectorizer(vocabulary=VOCABULARY)\n",
    "        self.output_vectorizer = CharVectorizer(vocabulary=DIGITS, max_sequence_len=8)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(math.ceil(self.n_examples / self.batch_size))\n",
    "    \n",
    "    @property\n",
    "    def input_sequence_len(self):\n",
    "        return self.input_vectorizer.max_sequence_len\n",
    "    \n",
    "    @property\n",
    "    def input_vocab_size(self):\n",
    "        return len(self.input_vectorizer.vocabulary)\n",
    "    \n",
    "    @property\n",
    "    def output_sequence_len(self):\n",
    "        return self.output_vectorizer.max_sequence_len\n",
    "    \n",
    "    @property\n",
    "    def output_vocab_size(self):\n",
    "        return len(self.output_vectorizer.vocabulary)\n",
    "        \n",
    "    def generate_string_batch(self) -> Tuple[List[str], List[str]]:\n",
    "        input_strings: List[str] = []\n",
    "        output_strings: List[str] = []\n",
    "            \n",
    "        for _ in range(self.batch_size):\n",
    "            datestr, date, gen_dict = generate_date()\n",
    "            if date:\n",
    "                output_datestr = date.strftime(format=\"%Y%m%d\")\n",
    "            else:\n",
    "                output_datestr = \"\".join([UNK_TOKEN] * self.output_vectorizer.max_sequence_len)\n",
    "            input_strings.append(datestr)\n",
    "            output_strings.append(output_datestr)\n",
    "            \n",
    "        return input_strings, output_strings\n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        input_strings, output_strings = self.generate_string_batch()\n",
    "        inputs = {\"datestr\": self.input_vectorizer.transform(input_strings)}\n",
    "        outputs = {\"output_datestr\": self.output_vectorizer.transform(output_strings)}\n",
    "        return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 ms, sys: 6.16 ms, total: 28.6 ms\n",
      "Wall time: 37.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs, outputs = generator.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_acc(y_true, y_pred):\n",
    "    return K.mean(\n",
    "        K.all(\n",
    "            K.equal(\n",
    "                K.max(y_true, axis=-1),\n",
    "                K.cast(K.argmax(y_pred, axis=-1), K.floatx())\n",
    "            ),\n",
    "            axis=1)\n",
    "    )\n",
    "\n",
    "\n",
    "def lstm_encoder_decoder(\n",
    "    input_sequence_len: int,\n",
    "    input_vocab_size: int,\n",
    "    output_sequence_len: int,\n",
    "    output_vocab_size: int,\n",
    "    embedding_dim: int = 64,\n",
    "    lstm_hidden_dim: int = 64,\n",
    "    learning_rate: float = 1e-3,\n",
    "):\n",
    "    # Encoder\n",
    "    _input = Input(shape=(input_sequence_len,), dtype=\"int32\", name=\"datestr\")\n",
    "    embedding = Embedding(output_dim=embedding_dim, input_dim=input_vocab_size, mask_zero=True)(_input)\n",
    "    encoded = Bidirectional(LSTM(lstm_hidden_dim, return_sequences=False))(embedding)\n",
    "    \n",
    "    # Decoder\n",
    "    repeated = RepeatVector(output_sequence_len)(encoded)\n",
    "    decoded = LSTM(lstm_hidden_dim, return_sequences=True)(repeated)\n",
    "    _output = TimeDistributed(Dense(output_vocab_size, activation='softmax'))(decoded)\n",
    "    \n",
    "    model = Model(inputs=[_input], outputs={\"output_datestr\": _output})\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.3270 - accuracy: 0.5193WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.3268 - accuracy: 0.5194WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - 301s 193ms/step - loss: 1.3268 - accuracy: 0.5194 - val_loss: 1.0830 - val_accuracy: 0.6066\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7728 - accuracy: 0.7243WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7726 - accuracy: 0.7243WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - 245s 156ms/step - loss: 0.7726 - accuracy: 0.7243 - val_loss: 0.4970 - val_accuracy: 0.8364\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.8933WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8934WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - 235s 150ms/step - loss: 0.3437 - accuracy: 0.8934 - val_loss: 0.2399 - val_accuracy: 0.9272\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9405WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9405WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1563/1563 [==============================] - 235s 151ms/step - loss: 0.2017 - accuracy: 0.9405 - val_loss: 0.1651 - val_accuracy: 0.9499\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1008/1563 [==================>...........] - ETA: 1:07 - loss: 0.1611 - accuracy: 0.9504"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=2, restore_best_weights=True\n",
    ")\n",
    "\n",
    "gen_train = DataGenerator()\n",
    "gen_val = DataGenerator()\n",
    "\n",
    "model = lstm_encoder_decoder(\n",
    "    input_sequence_len=gen_train.input_sequence_len,                                                                                                                                                                       \n",
    "    input_vocab_size=gen_train.input_vocab_size,\n",
    "    output_sequence_len=gen_train.output_sequence_len,\n",
    "    output_vocab_size=gen_train.output_vocab_size,                                                                                                             \n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    gen_train,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=gen_val,\n",
    "    max_queue_size=20,\n",
    "    workers=2,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "§###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=2, restore_best_weights=True\n",
    ")\n",
    "\n",
    "gen_train = DataGenerator()\n",
    "gen_val = DataGenerator()\n",
    "\n",
    "model = lstm_encoder_decoder(\n",
    "    input_sequence_len=gen_train.input_sequence_len,                                                                                                                                                                       \n",
    "    input_vocab_size=gen_train.input_vocab_size,\n",
    "    output_sequence_len=gen_train.output_sequence_len,\n",
    "    output_vocab_size=gen_train.output_vocab_size,                                                                                                             \n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    gen_train,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=gen_val,\n",
    "    max_queue_size=20,\n",
    "    workers=2,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lazydate-Xz_VEgM_-py3.7",
   "language": "python",
   "name": "lazydate-xz_vegm_-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
