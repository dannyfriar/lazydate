{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from typing import List, Tuple, Dict, Optional, Union, Any\n",
    "\n",
    "import numpy as np\n",
    "import babel\n",
    "import nlpaug.augmenter.char as nac\n",
    "from babel.dates import format_date, format_datetime\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    TimeDistributed,\n",
    "    Embedding,     \n",
    "    RepeatVector,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "os.chdir(\"/home/daniel/lazydate\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read wikitext-103\n",
    "with open('data/wiki.train.raw', 'r') as f:\n",
    "    wikitext = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_sentences = sent_tokenize(wikitext[:10000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(wiki_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_formats = [\"d\", \"dd\"]\n",
    "month_formats = [\"M\", \"MM\", \"MMM\", \"MMMM\", \"MMMM\", \"L\", \"LL\", \"LLL\", \"LLLL\", \"LLLL\"]\n",
    "year_formats = [\"yy\", \"yyyy\" ]\n",
    "\n",
    "second_formats = [\"s\", \"ss\"]\n",
    "minute_formats = [\"m\", \"mm\"]\n",
    "hour_formats = [\"h\", \"hh\", \"H\", \"HH\"]\n",
    "timezone_formats = [\"\", \"\", \"\", \"\", \"\", \"z\", \"zz\", \"zzz\", \"zzzz\"]\n",
    "time_separators = [\":\"]\n",
    "\n",
    "separator_frequency = {\n",
    "    \".\": 0.1, \n",
    "    \"/\": 0.15, \n",
    "    \"-\": 0.15, \n",
    "    \"''\": 0.1,\n",
    "    \" \": 0.5, \n",
    "}\n",
    "\n",
    "built_in_formats = [\"short\", \"medium\", \"long\", \"full\"]\n",
    "\n",
    "locales = babel.localedata.locale_identifiers()\n",
    "locales = [l for l in locales if \"en_\" in l]\n",
    "\n",
    "\n",
    "def random_date(n_years: int = 200) -> Tuple[datetime.datetime, Dict[str, int]]:\n",
    "    start_date = datetime.datetime(1900, 1, 1, 0, 0, 0)\n",
    "    gen_dict = {\n",
    "        \"days\": np.random.randint(0, n_years * 365),\n",
    "        \"hours\": np.random.randint(0, 24),\n",
    "        \"minutes\": np.random.randint(0, 60),\n",
    "        \"seconds\": np.random.randint(0, 60),\n",
    "    }\n",
    "    \n",
    "    date = start_date + datetime.timedelta(**gen_dict)\n",
    "    return date, gen_dict\n",
    "\n",
    "\n",
    "def random_format(date: datetime.datetime) -> Tuple[str, Dict[str, str]]:\n",
    "    possible_separators = list(separator_frequency.keys())\n",
    "    \n",
    "    if date.year >= datetime.datetime.now().year + 1:\n",
    "        year_format = np.random.choice(year_formats)\n",
    "    else:\n",
    "        year_format = \"yyyy\"\n",
    "    \n",
    "    append_time = np.random.rand() <= 0.5\n",
    "    drop_day = date.day == 1 and np.random.rand() <= 0.3\n",
    "    gen_dict = {\n",
    "        \"day\": np.random.choice(day_formats),\n",
    "        \"month\": np.random.choice(month_formats),\n",
    "        \"year\": year_format,\n",
    "        \"separator\": np.random.choice(\n",
    "            possible_separators, p=list(separator_frequency.values())\n",
    "        ),\n",
    "        \"append_time\": append_time,\n",
    "        \"drop_day\": drop_day,\n",
    "    }\n",
    "    if append_time:\n",
    "        time_gen_dict = {\n",
    "            \"second\": np.random.choice(second_formats),\n",
    "            \"minute\": np.random.choice(minute_formats),\n",
    "            \"hour\": np.random.choice(hour_formats),\n",
    "            \"timezone\": np.random.choice(timezone_formats),\n",
    "            \"time_separator\": np.random.choice(time_separators)\n",
    "        }\n",
    "    else:\n",
    "        time_gen_dict = {k: \"\" for k in [\"second\", \"minute\", \"hours\", \"timezone\", \"time_separator\"]}\n",
    "    gen_dict.update(time_gen_dict)\n",
    "    \n",
    "    sep = gen_dict[\"separator\"]\n",
    "    if sep != \"''\" and gen_dict[\"year\"] == \"yy\":\n",
    "        if np.random.random() <= 0.5:\n",
    "            gen_dict[\"year\"] = \"''\" + gen_dict[\"year\"]\n",
    "            \n",
    "    if drop_day:\n",
    "        format_date_str = f\"{gen_dict['month']}{sep}{gen_dict['year']}\"\n",
    "    else:\n",
    "        format_date_str = f\"{gen_dict['day']}{sep}{gen_dict['month']}{sep}{gen_dict['year']}\"\n",
    "    format_time_str = \"\"\n",
    "    \n",
    "    if append_time:\n",
    "        sep = gen_dict[\"time_separator\"]\n",
    "        format_time_str = f\" {gen_dict['hour']}{sep}{gen_dict['minute']}\"\n",
    "        if np.random.random() <= 0.5:\n",
    "            format_time_str += f\"{sep}{gen_dict['second']}\"\n",
    "        if np.random.random() <= 0.5:\n",
    "            format_time_str += f\" a\"  # AM / PM\n",
    "        if np.random.random() <= 0.5:\n",
    "            format_time_str += f\" {gen_dict['timezone']}\"    \n",
    "            \n",
    "    format_str = format_date_str + format_time_str\n",
    "    gen_dict[\"format_str\"] = format_str\n",
    "    return format_str, gen_dict\n",
    "\n",
    "\n",
    "def get_random_wiki_sentence(max_length: int = 150) -> str:\n",
    "    idx = np.random.randint(0, len(wiki_sentences))\n",
    "    return wiki_sentences[idx][:max_length]\n",
    "\n",
    "\n",
    "def random_noise_dict(\n",
    "    date: datetime.datetime, format_dict: Dict[str, str]\n",
    ") -> Dict[str, str]:\n",
    "\n",
    "    append_day_suffix = format_dict[\"day\"] == \"dd\" and np.random.random() <= 0.5\n",
    "    place_in_sentence = np.random.random() <= 0.5\n",
    "    \n",
    "    gen_dict = {\n",
    "        \"locale\": np.random.choice(locales),\n",
    "        \"append_day_suffix\": append_day_suffix,\n",
    "        \"aug_char_action\": np.random.choice([\"insert\", \"substitute\"]),\n",
    "        \"place_in_sentence\": place_in_sentence,\n",
    "        \"sentence\": get_random_wiki_sentence() if place_in_sentence else \"\",\n",
    "    }\n",
    "    \n",
    "    day_suffix = \"\"\n",
    "    if append_day_suffix:\n",
    "        if date.day in [1, 21, 31]:\n",
    "            day_suffix = \"st\"\n",
    "        elif date.day in [2, 22]:\n",
    "            day_suffix = \"st\"\n",
    "        elif date.day in [3, 23]:\n",
    "            day_suffix = \"rd\"\n",
    "        else:\n",
    "            day_suffix = \"th\"\n",
    "    gen_dict[\"day_suffix\"] = day_suffix\n",
    "    \n",
    "    return gen_dict\n",
    "\n",
    "\n",
    "def put_datestr_in_sentence(datestr: str, sentence: str):\n",
    "    split_sentence = sentence.split(\" \")    \n",
    "    idx = np.random.randint(0, len(split_sentence))\n",
    "    split_sentence[idx] = datestr\n",
    "    return \" \".join(split_sentence)\n",
    "\n",
    "\n",
    "def apply_noise(datestr: str, format_dict: Dict[str, str], noise_dict: Dict[str, Any]) -> str:\n",
    "    out = datestr\n",
    "    sep = format_dict[\"separator\"]\n",
    "    sep = sep[0] if len(sep) > 1 else sep\n",
    "    \n",
    "    date_parts = datestr.split(sep)\n",
    "    \n",
    "    if noise_dict[\"append_day_suffix\"]:\n",
    "        date_parts[0] = date_parts[0] + noise_dict[\"day_suffix\"]\n",
    "        \n",
    "    # Add spelling mistake to month name\n",
    "    if len(format_dict[\"month\"]) > 2 and np.random.random() <= 0.3:\n",
    "        aug = nac.RandomCharAug(\n",
    "            action=noise_dict[\"aug_char_action\"],\n",
    "            aug_char_min=1, \n",
    "            aug_char_max=1,\n",
    "        )\n",
    "        date_parts[1] = aug.augment(date_parts[1])\n",
    "        \n",
    "    out = f\"{sep}\".join(date_parts)\n",
    "    \n",
    "    if noise_dict[\"place_in_sentence\"]:\n",
    "        out = put_datestr_in_sentence(out, noise_dict[\"sentence\"])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def generate_date(\n",
    "    no_date_prob: float = 0.1\n",
    ") -> Tuple[str, datetime.datetime, Dict[str, Any]]:\n",
    "    date, date_gen_dict = random_date()\n",
    "    format_str, format_gen_dict = random_format(date)\n",
    "    noise_gen_dict = random_noise_dict(date, format_gen_dict)\n",
    "\n",
    "    datestr = format_datetime(\n",
    "        date, format=format_str, locale=noise_gen_dict[\"locale\"],\n",
    "    )\n",
    "    datestr = apply_noise(datestr, format_gen_dict, noise_gen_dict)\n",
    "    \n",
    "    gen_dict = date_gen_dict\n",
    "    gen_dict.update(format_gen_dict)\n",
    "    gen_dict.update(noise_gen_dict)\n",
    "    gen_dict[\"no_date\"] = False\n",
    "    \n",
    "    # Example with no date\n",
    "    if np.random.random() <= no_date_prob:\n",
    "        date = None\n",
    "        datestr = get_random_wiki_sentence()\n",
    "        gen_dict[\"no_date\"] = True\n",
    "    \n",
    "    return datestr, date, gen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date string: He that wanders about these wilds , either procures recommendations to those whose habitations 19 1 1924 near his way , or , when night and weariness come u\n",
      "\n",
      "Correct Date: 1924-01-19 18:23:35\n",
      "\n",
      "CPU times: user 1.29 ms, sys: 96 µs, total: 1.39 ms\n",
      "Wall time: 1.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "datestr, date, gen_dict = generate_date()\n",
    "print(f\"Date string: {datestr}\\n\")\n",
    "print(f\"Correct Date: {date}\\n\")\n",
    "# print(gen_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTERS = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "DIGITS = \"0123456789\"\n",
    "SYMBOLS = \"£&()[]+-/*;:@_\\\\\\\"'#\" + \"€$%!?,. \"\n",
    "VOCABULARY = LETTERS + DIGITS + SYMBOLS\n",
    "\n",
    "MAX_SEQUENCE_LEN = 200\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "class CharVectorizer:\n",
    "    def __init__(\n",
    "        self, vocabulary: str, max_sequence_len: int = MAX_SEQUENCE_LEN\n",
    "    ):\n",
    "        self.max_sequence_len = max_sequence_len\n",
    "        self.encoder: Dict[str, int] = {c: idx for idx, c in enumerate(list(vocabulary))}\n",
    "        self.encoder[UNK_TOKEN] = len(self.encoder)\n",
    "        \n",
    "    @property\n",
    "    def decoder(self):\n",
    "        return {v: k for k, v in self.encoder.items()}\n",
    "\n",
    "    @property\n",
    "    def vocabulary(self):\n",
    "        return sorted(list(self.encoder.keys()))\n",
    "\n",
    "    def transform(self, inputs: List[str]) -> np.ndarray:\n",
    "        outputs = [self._get_char_indices_for_word(s) for s in inputs]\n",
    "        outputs = np.array(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def inverse_transform(self, arr: np.ndarray) -> List[str]:\n",
    "        output_strings: List[str] = []\n",
    "            \n",
    "        for output in arr:\n",
    "            decoded_output = [self.decoder[o] for o in output]\n",
    "            if \"<unk>\" in decoded_output:\n",
    "                output_strings.append(\"\")\n",
    "            else:\n",
    "                output_strings.append(\"\".join(decoded_output))\n",
    "                \n",
    "        return output_strings\n",
    "        \n",
    "    def _get_char_indices_for_word(self, text: str) -> np.ndarray:\n",
    "        next_arr = np.zeros([self.max_sequence_len], dtype=np.int32)\n",
    "\n",
    "        for idx, token in enumerate(text):\n",
    "            if idx < self.max_sequence_len:  # truncate end of sentence if too long\n",
    "                if token in self.encoder:\n",
    "                    vocab_idx = self.encoder[token]\n",
    "                else:\n",
    "                    vocab_idx = self.encoder[UNK_TOKEN]\n",
    "                next_arr[idx] = vocab_idx\n",
    "        return next_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, batch_size=32, n_examples=50000):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_examples = n_examples\n",
    "        self.input_vectorizer = CharVectorizer(vocabulary=VOCABULARY)\n",
    "        self.output_vectorizer = CharVectorizer(vocabulary=DIGITS, max_sequence_len=8)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(math.ceil(self.n_examples / self.batch_size))\n",
    "    \n",
    "    @property\n",
    "    def input_sequence_len(self):\n",
    "        return self.input_vectorizer.max_sequence_len\n",
    "    \n",
    "    @property\n",
    "    def input_vocab_size(self):\n",
    "        return len(self.input_vectorizer.vocabulary)\n",
    "    \n",
    "    @property\n",
    "    def output_sequence_len(self):\n",
    "        return self.output_vectorizer.max_sequence_len\n",
    "    \n",
    "    @property\n",
    "    def output_vocab_size(self):\n",
    "        return len(self.output_vectorizer.vocabulary)\n",
    "        \n",
    "    def generate_string_batch(self) -> Tuple[List[str], List[str]]:\n",
    "        input_strings: List[str] = []\n",
    "        output_strings: List[str] = []\n",
    "            \n",
    "        for _ in range(self.batch_size):\n",
    "            datestr, date, gen_dict = generate_date()\n",
    "            if date:\n",
    "                output_datestr = date.strftime(format=\"%Y%m%d\")\n",
    "            else:\n",
    "                output_datestr = \"\".join([UNK_TOKEN] * self.output_vectorizer.max_sequence_len)\n",
    "            input_strings.append(datestr)\n",
    "            output_strings.append(output_datestr)\n",
    "            \n",
    "        return input_strings, output_strings\n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        input_strings, output_strings = self.generate_string_batch()\n",
    "        inputs = {\"datestr\": self.input_vectorizer.transform(input_strings)}\n",
    "        outputs = {\"output_datestr\": self.output_vectorizer.transform(output_strings)}\n",
    "        return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 ms, sys: 12 µs, total: 20.7 ms\n",
      "Wall time: 19.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs, outputs = generator.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_accuracy(y_true, y_pred):\n",
    "    y_pred = K.cast(K.argmax(y_pred, axis=-1), \"float32\")\n",
    "    diff = K.abs(y_pred - y_true)\n",
    "    errors = K.sum(diff, axis=-1)\n",
    "    errors = K.clip(errors, 0, 1)\n",
    "    errors = K.cast(errors, K.floatx())\n",
    "    return 1.0 - K.mean(errors)\n",
    "\n",
    "\n",
    "def lstm_encoder_decoder(\n",
    "    input_sequence_len: int,\n",
    "    input_vocab_size: int,\n",
    "    output_sequence_len: int,\n",
    "    output_vocab_size: int,\n",
    "    embedding_dim: int = 64,\n",
    "    lstm_hidden_dim: int = 64,\n",
    "    learning_rate: float = 1e-3,\n",
    "):\n",
    "    # Encoder\n",
    "    _input = Input(shape=(input_sequence_len,), dtype=\"int32\", name=\"datestr\")\n",
    "    embedding = Embedding(output_dim=embedding_dim, input_dim=input_vocab_size, mask_zero=False)(_input)\n",
    "    encoded = Bidirectional(LSTM(lstm_hidden_dim, return_sequences=False))(embedding)\n",
    "    \n",
    "    # Decoder\n",
    "    repeated = RepeatVector(output_sequence_len)(encoded)\n",
    "    decoded = LSTM(lstm_hidden_dim, return_sequences=True)(repeated)\n",
    "    _output = TimeDistributed(Dense(output_vocab_size, activation='softmax'))(decoded)\n",
    "    \n",
    "    model = Model(inputs=[_input], outputs={\"output_datestr\": _output})\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer, loss='sparse_categorical_crossentropy', \n",
    "        metrics=[\"accuracy\", sequence_accuracy]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 227s 36ms/step - loss: 1.1979 - accuracy: 0.5514 - sequence_accuracy: 0.0794 - val_loss: 0.8049 - val_accuracy: 0.7019 - val_sequence_accuracy: 0.1149\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 226s 36ms/step - loss: 0.3702 - accuracy: 0.8793 - sequence_accuracy: 0.5110 - val_loss: 0.1035 - val_accuracy: 0.9827 - val_sequence_accuracy: 0.9169\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 227s 36ms/step - loss: 0.0624 - accuracy: 0.9887 - sequence_accuracy: 0.9510 - val_loss: 0.0356 - val_accuracy: 0.9938 - val_sequence_accuracy: 0.9747\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 226s 36ms/step - loss: 0.0343 - accuracy: 0.9933 - sequence_accuracy: 0.9733 - val_loss: 0.0354 - val_accuracy: 0.9928 - val_sequence_accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 227s 36ms/step - loss: 0.0229 - accuracy: 0.9953 - sequence_accuracy: 0.9821 - val_loss: 0.0196 - val_accuracy: 0.9968 - val_sequence_accuracy: 0.9885\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 226s 36ms/step - loss: 0.0170 - accuracy: 0.9963 - sequence_accuracy: 0.9861 - val_loss: 0.0174 - val_accuracy: 0.9960 - val_sequence_accuracy: 0.9850\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 228s 36ms/step - loss: 0.0142 - accuracy: 0.9968 - sequence_accuracy: 0.9883 - val_loss: 0.0101 - val_accuracy: 0.9975 - val_sequence_accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 226s 36ms/step - loss: 0.0123 - accuracy: 0.9972 - sequence_accuracy: 0.9897 - val_loss: 0.0134 - val_accuracy: 0.9968 - val_sequence_accuracy: 0.9881\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 225s 36ms/step - loss: 0.0111 - accuracy: 0.9974 - sequence_accuracy: 0.9903 - val_loss: 0.0072 - val_accuracy: 0.9984 - val_sequence_accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 227s 36ms/step - loss: 0.0105 - accuracy: 0.9976 - sequence_accuracy: 0.9914 - val_loss: 0.0096 - val_accuracy: 0.9979 - val_sequence_accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=2, restore_best_weights=True\n",
    ")\n",
    "\n",
    "gen_train = DataGenerator(n_examples=200000)\n",
    "gen_val = DataGenerator(n_examples=10000)\n",
    "\n",
    "model = lstm_encoder_decoder(\n",
    "    input_sequence_len=gen_train.input_sequence_len,                                                                                                                                                                       \n",
    "    input_vocab_size=gen_train.input_vocab_size,\n",
    "    output_sequence_len=gen_train.output_sequence_len,\n",
    "    output_vocab_size=gen_train.output_vocab_size,                                                                                                             \n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    gen_train,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=gen_val,\n",
    "    max_queue_size=20,\n",
    "    workers=2,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_test = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18d0079e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "input_strings, output_strings = gen_test.generate_string_batch()\n",
    "inputs = {\"datestr\": gen_test.input_vectorizer.transform(input_strings)}\n",
    "outputs = {\"output_datestr\": gen_test.output_vectorizer.transform(output_strings)}\n",
    "\n",
    "x_pred = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8, 11)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred[\"output_datestr\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_arrays = np.argmax(x_pred[\"output_datestr\"], axis=-1)\n",
    "pred_strings = gen_test.output_vectorizer.inverse_transform(output_arrays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _input, p, gt in zip(input_strings, pred_strings, output_strings):\n",
    "    if p != gt and \"<unk>\" not in gt:\n",
    "        print(f\"Input string: {_input}\")\n",
    "        print(f\"Input string: {len(_input)}\")\n",
    "        print(f\"Predicted: {p}\")\n",
    "        print(f\"Ground Truth: {gt}\")\n",
    "        print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18d0079e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['19421201']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try on random examples\n",
    "input_strings = [\n",
    "    \"12-1942\",\n",
    "]\n",
    "\n",
    "vectorizer = CharVectorizer(vocabulary=VOCABULARY)\n",
    "out_vectorizer = CharVectorizer(vocabulary=DIGITS, max_sequence_len=8)\n",
    "\n",
    "model_inputs = {\n",
    "    \"datestr\": vectorizer.transform(input_strings)\n",
    "}\n",
    "\n",
    "\n",
    "_pred = model.predict(model_inputs)\n",
    "output_arrays = np.argmax(_pred[\"output_datestr\"], axis=-1)\n",
    "pred_strings = out_vectorizer.inverse_transform(output_arrays)\n",
    "pred_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 9, 4, 2, 1, 2, 2, 0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(_pred[\"output_datestr\"], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lazydate-dilt4lxy-py3.8",
   "language": "python",
   "name": "lazydate-dilt4lxy-py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
